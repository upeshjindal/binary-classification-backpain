{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>Col11</th>\n",
       "      <th>Col12</th>\n",
       "      <th>Class_att</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.027817</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>0.744503</td>\n",
       "      <td>12.5661</td>\n",
       "      <td>14.5386</td>\n",
       "      <td>15.30468</td>\n",
       "      <td>-28.658501</td>\n",
       "      <td>43.5123</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>0.415186</td>\n",
       "      <td>12.8874</td>\n",
       "      <td>17.5323</td>\n",
       "      <td>16.78486</td>\n",
       "      <td>-25.530607</td>\n",
       "      <td>16.1102</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>0.474889</td>\n",
       "      <td>26.8343</td>\n",
       "      <td>17.4861</td>\n",
       "      <td>16.65897</td>\n",
       "      <td>-29.031888</td>\n",
       "      <td>19.2221</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>0.369345</td>\n",
       "      <td>23.5603</td>\n",
       "      <td>12.7074</td>\n",
       "      <td>11.42447</td>\n",
       "      <td>-30.470246</td>\n",
       "      <td>18.8329</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>0.543360</td>\n",
       "      <td>35.4940</td>\n",
       "      <td>15.9546</td>\n",
       "      <td>8.87237</td>\n",
       "      <td>-16.378376</td>\n",
       "      <td>24.9171</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Col1       Col2       Col3       Col4        Col5       Col6  \\\n",
       "0  63.027817  22.552586  39.609117  40.475232   98.672917  -0.254400   \n",
       "1  39.056951  10.060991  25.015378  28.995960  114.405425   4.564259   \n",
       "2  68.832021  22.218482  50.092194  46.613539  105.985135  -3.530317   \n",
       "3  69.297008  24.652878  44.311238  44.644130  101.868495  11.211523   \n",
       "4  49.712859   9.652075  28.317406  40.060784  108.168725   7.918501   \n",
       "\n",
       "       Col7     Col8     Col9     Col10      Col11    Col12 Class_att  \\\n",
       "0  0.744503  12.5661  14.5386  15.30468 -28.658501  43.5123  Abnormal   \n",
       "1  0.415186  12.8874  17.5323  16.78486 -25.530607  16.1102  Abnormal   \n",
       "2  0.474889  26.8343  17.4861  16.65897 -29.031888  19.2221  Abnormal   \n",
       "3  0.369345  23.5603  12.7074  11.42447 -30.470246  18.8329  Abnormal   \n",
       "4  0.543360  35.4940  15.9546   8.87237 -16.378376  24.9171  Abnormal   \n",
       "\n",
       "   Unnamed: 13  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/Dataset_spine.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Class_att', ylabel='count'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"Class_att\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Upesh\\AppData\\Local\\Temp\\ipykernel_11200\\346891693.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Class_att\"].replace(encode_map, inplace=True)\n",
      "C:\\Users\\Upesh\\AppData\\Local\\Temp\\ipykernel_11200\\346891693.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"Class_att\"].replace(encode_map, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Encode output class\n",
    "# df[\"Class_att\"] = df[\"Class_att\"].astype(\"category\")\n",
    "\n",
    "encode_map = {\n",
    "    \"Abnormal\": 1,\n",
    "    \"Normal\": 0\n",
    "}\n",
    "\n",
    "df[\"Class_att\"].replace(encode_map, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "305    0\n",
       "306    0\n",
       "307    0\n",
       "308    0\n",
       "309    0\n",
       "Name: Class_att, Length: 310, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class_att\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.head()=        Col1       Col2       Col3       Col4        Col5       Col6  \\\n",
      "0  63.027817  22.552586  39.609117  40.475232   98.672917  -0.254400   \n",
      "1  39.056951  10.060991  25.015378  28.995960  114.405425   4.564259   \n",
      "2  68.832021  22.218482  50.092194  46.613539  105.985135  -3.530317   \n",
      "3  69.297008  24.652878  44.311238  44.644130  101.868495  11.211523   \n",
      "4  49.712859   9.652075  28.317406  40.060784  108.168725   7.918501   \n",
      "\n",
      "       Col7     Col8     Col9     Col10      Col11    Col12  \n",
      "0  0.744503  12.5661  14.5386  15.30468 -28.658501  43.5123  \n",
      "1  0.415186  12.8874  17.5323  16.78486 -25.530607  16.1102  \n",
      "2  0.474889  26.8343  17.4861  16.65897 -29.031888  19.2221  \n",
      "3  0.369345  23.5603  12.7074  11.42447 -30.470246  18.8329  \n",
      "4  0.543360  35.4940  15.9546   8.87237 -16.378376  24.9171  \n",
      "y.head()=0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: Class_att, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, 0:12]\n",
    "y = df.iloc[:, 12]\n",
    "\n",
    "print(f\"{X.head()=}\")\n",
    "print(f\"{y.head()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=(207, 12)\n",
      "X_test.shape=(103, 12)\n",
      "y_train.shape=(207,)\n",
      "y_test.shape=(103,)\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "# Split into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=RANDOM_SEED)\n",
    "\n",
    "print(f\"{X_train.shape=}\")\n",
    "print(f\"{X_test.shape=}\")\n",
    "print(f\"{y_train.shape=}\")\n",
    "print(f\"{y_test.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize input\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.37202001,  0.25923767, -1.71333214, ..., -0.80599815,\n",
       "        -0.07495636,  1.20007508],\n",
       "       [ 0.24994168,  0.35515544,  0.2076004 , ..., -0.17433336,\n",
       "         1.31921218, -0.81532979],\n",
       "       [-0.68278003, -0.3841279 , -0.8065591 , ...,  0.13307376,\n",
       "        -1.01230518, -1.12221813],\n",
       "       ...,\n",
       "       [ 0.31790653, -0.74297648,  0.38824039, ..., -0.3662492 ,\n",
       "         1.63203394,  0.85631296],\n",
       "       [-0.47210125, -0.84342974,  0.34648583, ..., -0.60404398,\n",
       "         1.56500092,  1.01529103],\n",
       "       [ 0.62841697, -0.36403129,  0.58481187, ...,  0.14065634,\n",
       "         1.59316912,  0.84577355]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TrainData at 0x1b34925a1d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_train, y_train):\n",
    "        \n",
    "        self.X_data = X_train\n",
    "        self.y_data = y_train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "    \n",
    "train_dataset = TrainData(X_train=torch.FloatTensor(X_train), y_train=torch.FloatTensor(y_train))\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TestData at 0x1b347870a10>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_test) -> None:\n",
    "        \n",
    "        self.X_data = X_test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "    \n",
    "test_dataset = TestData(X_test=torch.FloatTensor(X_test))\n",
    "test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader=<torch.utils.data.dataloader.DataLoader object at 0x000001B3422405D0>\n",
      "test_loader=<torch.utils.data.dataloader.DataLoader object at 0x000001B347162010>\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"{train_loader=}\")\n",
    "print(f\"{test_loader=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 3.5547e-01, -6.6968e-01,  3.1750e-01,  9.2401e-01, -7.4822e-01,\n",
      "          6.9510e-01, -1.0185e+00, -9.8137e-02, -4.3441e-01,  1.5069e+00,\n",
      "         -8.2684e-01, -9.4811e-01],\n",
      "        [-6.7426e-01, -6.5424e-01,  1.7625e-01, -3.9831e-01,  5.4191e-01,\n",
      "         -6.5459e-01,  9.8217e-01,  1.3737e+00, -2.8106e-01,  1.2538e+00,\n",
      "          7.7243e-01,  1.2826e+00],\n",
      "        [ 1.4087e+00,  2.5384e+00,  6.3021e-01,  7.7486e-03, -2.8319e-01,\n",
      "          1.5867e-02,  5.0265e-01, -1.4256e+00, -1.6935e+00, -7.1854e-01,\n",
      "         -5.1115e-01, -3.4192e-01],\n",
      "        [-6.1681e-01,  1.1050e-01,  6.2764e-02, -8.6333e-01,  1.6358e+00,\n",
      "         -3.8518e-01, -1.2992e+00,  5.9305e-01,  1.8380e+00, -1.2173e+00,\n",
      "         -7.1660e-01,  1.2816e+00],\n",
      "        [-6.5955e-01, -1.1761e+00,  3.4973e-01, -1.2306e-02, -1.8389e+00,\n",
      "          1.7106e-01, -2.4308e-01,  1.1809e+00, -4.1841e-01, -1.9538e-01,\n",
      "         -9.5997e-01,  1.3958e+00],\n",
      "        [-5.0872e-01, -1.0953e+00, -9.0189e-01,  1.2292e-01, -1.5793e-01,\n",
      "         -6.4992e-01, -1.5956e+00, -2.6390e-01, -1.4684e+00, -7.3610e-01,\n",
      "          1.0058e+00, -1.1108e+00],\n",
      "        [-1.3573e-01, -4.9009e-02, -4.5689e-01, -1.3837e-01, -3.7907e-01,\n",
      "         -5.2001e-01, -8.8023e-01,  5.4915e-01, -1.0273e+00, -1.6379e+00,\n",
      "         -1.4527e+00, -1.5803e-01],\n",
      "        [-1.9581e-01, -4.0198e-01,  6.6635e-01,  3.3505e-02, -1.8650e-01,\n",
      "          1.2975e-01,  8.5293e-01, -1.3866e+00,  1.0505e+00,  1.5337e+00,\n",
      "          4.1467e-01, -1.7242e+00],\n",
      "        [-2.7372e-01, -7.5192e-01, -1.6421e-01,  1.8055e-01,  3.5484e-01,\n",
      "         -4.4002e-01, -3.0694e-01,  8.2820e-01,  5.6542e-01,  5.5239e-01,\n",
      "         -3.7592e-01, -1.1490e+00],\n",
      "        [ 1.2831e+00,  3.3021e-01,  1.1160e+00,  1.4018e+00,  6.7621e-02,\n",
      "          7.3422e-01, -7.3056e-01, -6.6151e-01,  1.5216e+00,  9.2028e-01,\n",
      "          7.8385e-01,  6.7766e-01],\n",
      "        [-8.9812e-01, -2.9016e-01, -7.4116e-01, -9.3964e-01,  1.2630e+00,\n",
      "         -4.8433e-01, -6.7911e-01, -1.0009e+00,  1.1422e+00, -5.3996e-01,\n",
      "          7.0424e-01, -3.3593e-01],\n",
      "        [-1.3842e+00, -5.4854e-01, -2.0033e+00, -1.3769e+00, -9.2502e-01,\n",
      "         -7.3054e-01,  9.5880e-01, -6.5921e-01, -1.0817e+00,  1.6096e+00,\n",
      "          9.0470e-01, -5.6796e-01],\n",
      "        [-1.4824e+00, -1.3861e+00, -1.4410e+00, -9.1255e-01,  7.7518e-01,\n",
      "         -6.8871e-01, -2.9236e-01, -1.3277e+00, -4.9758e-01,  4.3923e-01,\n",
      "          9.2435e-01, -1.4846e+00],\n",
      "        [-4.2062e-01,  2.6492e-02,  1.5435e+00, -5.5434e-01,  1.4626e+00,\n",
      "          7.2011e-01, -1.6488e+00, -7.9771e-02, -1.3007e+00,  4.4448e-02,\n",
      "          8.6576e-01, -1.6394e-01],\n",
      "        [-9.3961e-01,  2.8218e-01, -9.0189e-01, -1.3953e+00,  4.9858e-01,\n",
      "         -7.1710e-01, -1.6112e+00,  6.7466e-01,  9.6420e-01,  9.5191e-01,\n",
      "         -8.4529e-01, -2.0218e-01],\n",
      "        [-1.6687e-01, -1.6547e-02, -5.0468e-01, -2.0088e-01,  6.9323e-01,\n",
      "         -4.7960e-02,  1.1333e+00, -1.7505e-01, -1.2420e+00,  1.5042e+00,\n",
      "         -1.7276e+00,  5.2813e-01],\n",
      "        [ 1.2291e+00,  2.3792e-01,  6.0992e-01,  1.3979e+00, -2.3136e+00,\n",
      "          4.5255e-01, -1.3842e+00,  2.3719e-01, -9.5456e-02, -7.3220e-02,\n",
      "         -1.4910e+00,  1.0210e-01],\n",
      "        [ 4.2546e-01,  8.2778e-01, -9.1660e-02, -4.0678e-02, -4.0524e-01,\n",
      "         -6.9441e-01,  7.2358e-01, -1.0062e+00, -1.3972e+00, -1.4613e+00,\n",
      "          7.8637e-01,  1.2565e-01],\n",
      "        [ 7.5783e-01,  2.0559e-01,  9.7067e-01,  8.2048e-01, -1.2808e-01,\n",
      "         -1.4037e-02, -1.2084e-01, -9.3786e-01,  4.6132e-01,  6.1280e-01,\n",
      "         -6.0360e-01,  1.4329e+00],\n",
      "        [ 2.2512e-01, -2.9669e-01, -1.5645e-01,  4.9551e-01, -5.2934e-01,\n",
      "          1.4495e-01, -1.2707e+00, -1.6410e-02,  5.5961e-02,  4.7263e-01,\n",
      "         -8.4379e-01, -1.5903e+00],\n",
      "        [-8.8119e-01, -1.6123e+00, -2.7144e-01,  1.2352e-02, -7.9061e-01,\n",
      "          4.1884e-01,  2.9182e-02, -1.1496e-01,  5.0666e-01,  1.9534e-02,\n",
      "          1.5351e+00, -1.1620e+00],\n",
      "        [ 8.4148e-01,  1.9459e-01,  1.4265e+00,  9.3476e-01,  7.8157e-01,\n",
      "          1.1784e+00,  1.5494e+00, -9.1810e-01, -8.4297e-01, -1.1559e+00,\n",
      "          1.0774e+00, -1.3533e+00],\n",
      "        [-3.2075e-01,  3.9261e-01, -1.2298e+00, -6.8481e-01, -3.3458e-01,\n",
      "         -6.5505e-01, -1.5011e+00, -2.1557e-01,  1.5241e+00, -1.6296e+00,\n",
      "          1.5871e+00,  1.6835e+00],\n",
      "        [ 6.1983e-01, -6.9061e-01,  1.4456e+00,  1.2754e+00,  5.2669e-02,\n",
      "          1.6686e-01, -1.0922e+00, -1.4023e+00, -3.2473e-01, -1.4767e+00,\n",
      "          6.2640e-01,  1.6827e+00],\n",
      "        [ 1.1766e-01,  2.8362e-01,  1.1339e-01, -4.9752e-02,  8.8857e-03,\n",
      "         -5.2498e-01, -9.2060e-01, -7.6518e-01, -1.6139e+00,  6.1551e-02,\n",
      "         -4.9537e-01,  1.4817e+00],\n",
      "        [ 6.7382e-01,  7.2387e-01, -4.0840e-01,  3.4875e-01,  1.0259e-01,\n",
      "          3.3153e-02, -2.4859e-01, -1.3911e+00,  1.0895e+00, -1.6487e+00,\n",
      "          7.2986e-01, -1.0844e+00],\n",
      "        [ 4.4760e-01, -1.0188e+00,  4.5564e-02,  1.2870e+00, -1.6515e+00,\n",
      "          4.0210e-01,  1.6404e+00, -3.8517e-01, -9.7894e-01, -1.5798e+00,\n",
      "         -1.4989e+00,  6.6069e-01],\n",
      "        [-6.0562e-01, -4.0119e-01,  5.5587e-02, -4.8898e-01,  6.2197e-01,\n",
      "         -6.3129e-01,  9.1963e-01,  1.4831e+00, -1.6048e+00,  1.2814e+00,\n",
      "          5.8911e-01, -1.3249e+00],\n",
      "        [-1.0922e+00,  1.0633e-01, -9.5863e-01, -1.4658e+00,  1.9650e-01,\n",
      "         -6.8278e-01, -1.6281e+00,  1.2404e+00, -1.3963e+00, -1.3623e+00,\n",
      "          3.3658e-01, -1.3307e+00],\n",
      "        [-8.3967e-01,  5.0613e-02, -1.3115e+00, -1.1050e+00, -4.7236e-02,\n",
      "         -5.0624e-01,  1.2166e+00,  7.5619e-01,  2.4330e-01,  5.4348e-01,\n",
      "          8.6965e-01,  9.4526e-01],\n",
      "        [-1.6153e+00, -9.5292e-01, -1.5099e+00, -1.3866e+00, -3.7693e-01,\n",
      "         -5.3546e-01,  8.5043e-01, -1.3233e+00, -1.4410e+00, -2.5605e-02,\n",
      "         -1.0344e+00, -1.2612e+00],\n",
      "        [-4.9509e-01, -1.0728e+00, -1.1347e+00,  1.2446e-01, -3.3625e-02,\n",
      "         -6.7087e-01, -1.5348e+00,  1.7005e+00,  2.6477e-02,  3.8322e-02,\n",
      "          3.6311e-01,  5.3735e-01],\n",
      "        [-8.7906e-01, -1.6546e+00, -7.3166e-01,  4.4881e-02, -1.6138e+00,\n",
      "         -5.0642e-02, -1.0311e+00, -1.2929e+00, -1.7025e-01, -7.3784e-01,\n",
      "          6.0726e-01, -4.3122e-02],\n",
      "        [ 5.3042e-02, -1.2201e+00,  5.0618e-01,  9.2619e-01, -7.5853e-01,\n",
      "          1.0722e-01,  1.5692e+00,  1.6329e+00,  1.5378e+00,  7.4129e-03,\n",
      "          9.9974e-01,  7.7528e-01],\n",
      "        [-1.9230e+00, -6.4686e-01, -2.0935e+00, -1.9938e+00,  5.2698e-01,\n",
      "         -8.9530e-01, -2.8489e-01, -1.3046e+00, -1.2824e+00,  1.2948e+00,\n",
      "         -4.7258e-01,  1.6916e+00],\n",
      "        [ 1.0151e+00,  1.4098e+00,  1.0547e+00,  3.0073e-01, -5.1061e-01,\n",
      "          1.1131e+00, -1.1172e+00, -1.1904e+00,  6.2951e-02, -1.2795e-01,\n",
      "          9.5512e-01, -7.0046e-01],\n",
      "        [ 8.7737e-01, -2.7516e-01, -1.0437e+00,  1.3111e+00, -9.0567e-01,\n",
      "          2.7493e-01,  1.7910e+00,  5.0240e-01, -1.4025e+00,  8.0261e-02,\n",
      "          1.2324e+00,  5.0827e-01],\n",
      "        [ 1.1884e+00,  1.7721e+00,  1.9411e+00,  2.6640e-01,  5.5801e-01,\n",
      "          1.8467e+00, -1.3574e+00, -1.0968e+00,  9.2150e-01, -7.5091e-01,\n",
      "          1.4613e+00,  9.4806e-01],\n",
      "        [-1.0224e+00,  9.8147e-02, -1.7513e+00, -1.3712e+00, -1.6783e-02,\n",
      "         -5.9334e-01, -3.5778e-01,  8.0148e-03, -1.7158e+00, -7.1028e-01,\n",
      "          5.5535e-01, -1.3598e+00],\n",
      "        [-7.9555e-01, -6.5725e-01, -4.7189e-01, -5.5067e-01,  9.2249e-01,\n",
      "         -7.2877e-01,  1.8292e+00,  6.5245e-01,  1.5747e+00,  1.5194e+00,\n",
      "          2.5911e-02,  7.7914e-01],\n",
      "        [ 6.4936e-02,  3.7951e-01,  7.7407e-01, -1.8438e-01, -1.0724e-01,\n",
      "          1.9601e+00, -3.0280e-01, -4.6972e-01, -1.2327e+00,  1.6448e+00,\n",
      "         -1.3507e+00,  8.8937e-01],\n",
      "        [-6.1099e-01, -1.1865e+00,  2.6137e-01,  5.6845e-02,  1.4734e+00,\n",
      "         -1.5139e-01, -9.0983e-01,  1.0318e+00, -8.9466e-01, -3.5783e-01,\n",
      "          1.2614e+00, -2.1698e-01],\n",
      "        [ 1.6450e-02,  9.6052e-02,  4.7169e-01, -4.6646e-02,  5.9196e-02,\n",
      "         -9.5025e-02, -3.4592e-01,  2.6530e-01,  6.0425e-01, -1.0228e+00,\n",
      "         -1.4837e+00,  1.3557e+00],\n",
      "        [-4.5406e-01, -1.0324e-01, -9.0189e-01, -5.0563e-01,  8.5944e-01,\n",
      "         -6.1952e-01, -1.6526e+00,  1.3281e+00,  2.3719e-01, -2.1757e-01,\n",
      "         -9.6381e-01,  9.0506e-01],\n",
      "        [-5.6407e-02, -3.1684e-01, -5.3487e-01,  1.5113e-01, -2.4324e-01,\n",
      "          1.1026e-01, -2.5267e-01,  1.5935e+00, -7.7848e-01, -4.3317e-01,\n",
      "         -9.8636e-01, -1.4713e+00],\n",
      "        [ 1.1863e+00,  3.2462e+00,  8.5657e-02, -7.7365e-01, -6.2522e-01,\n",
      "          1.0378e+00, -1.3172e+00, -8.9053e-02, -7.9263e-01,  1.3325e+00,\n",
      "         -3.1653e-02,  1.3159e+00],\n",
      "        [ 1.0468e+00,  5.7119e-01,  2.4399e+00,  9.3117e-01,  3.5625e-01,\n",
      "          8.7591e-01,  1.5989e+00, -7.1158e-01,  5.9970e-01, -1.4649e+00,\n",
      "          1.1292e+00,  7.2588e-01],\n",
      "        [-5.4277e-01, -3.6820e-01, -9.3267e-01, -4.3214e-01,  4.4529e-02,\n",
      "         -5.6784e-01,  9.6064e-01,  1.2789e+00,  6.1582e-01,  8.5265e-01,\n",
      "          5.3846e-01, -9.5047e-01],\n",
      "        [ 3.3812e+00,  2.2424e+00, -3.1430e-03,  2.7282e+00, -2.9852e+00,\n",
      "          1.1947e+00,  4.4831e-01,  1.7293e+00, -6.1103e-01,  3.9759e-01,\n",
      "         -3.0169e-01, -4.5160e-01],\n",
      "        [ 1.2197e+00,  9.7932e-01,  5.6768e-01,  8.6419e-01,  1.2155e-01,\n",
      "          6.5872e-01,  1.6226e+00, -1.1214e-01,  1.6105e+00, -9.9151e-01,\n",
      "         -4.4682e-01,  4.7736e-01],\n",
      "        [-5.4388e-01, -8.1789e-01, -1.0626e+00, -1.1710e-01, -1.4995e+00,\n",
      "          2.0304e-02,  8.4088e-01,  1.0069e-01,  1.7133e+00, -9.2618e-01,\n",
      "          1.5154e+00, -6.7642e-01],\n",
      "        [-4.0824e-01,  2.1419e-01, -8.5237e-01, -6.7067e-01, -1.6017e-01,\n",
      "         -6.0249e-01, -1.4615e+00,  1.0478e+00,  1.7339e+00,  1.5864e+00,\n",
      "         -1.0086e+00,  1.2500e+00],\n",
      "        [-1.0849e+00, -8.1495e-01, -1.1276e+00, -8.0821e-01,  1.6332e+00,\n",
      "         -7.0698e-01,  1.0715e+00,  1.1936e+00,  1.9264e-01,  3.6444e-01,\n",
      "          7.3592e-01, -5.6991e-01],\n",
      "        [-7.4158e-01, -1.1531e-01, -6.1817e-01, -8.6333e-01,  6.3846e-02,\n",
      "         -4.1942e-01,  2.2637e-02,  2.8995e-01, -5.6977e-01, -1.4632e+00,\n",
      "          1.5183e+00, -8.0749e-01],\n",
      "        [-1.2323e+00, -1.0853e+00, -2.5469e-02, -8.0570e-01,  1.0764e+00,\n",
      "         -4.8715e-01, -1.5888e+00, -1.4615e-01, -4.9277e-01,  7.5510e-01,\n",
      "         -1.3283e+00,  1.1442e+00],\n",
      "        [ 1.7300e+00,  3.3332e+00,  1.1978e+00, -1.4245e-01,  1.2767e+00,\n",
      "          2.2953e+00, -1.5312e+00, -1.3704e-01, -1.1809e+00,  9.5486e-01,\n",
      "          1.6557e+00,  2.9791e-01],\n",
      "        [ 6.6033e-01,  3.3402e-01,  6.7896e-01,  6.0592e-01, -1.9052e-01,\n",
      "          1.6328e-01, -1.4766e+00, -1.6027e+00,  9.8684e-01,  9.4861e-02,\n",
      "          6.9584e-01, -8.2720e-01],\n",
      "        [-6.4466e-01,  5.1477e-02, -1.6421e-01, -8.5726e-01,  8.2725e-01,\n",
      "         -6.6722e-01,  9.6060e-01,  1.8184e+00,  4.7803e-01, -1.0246e-01,\n",
      "         -1.1908e+00, -1.4803e+00],\n",
      "        [ 1.0160e+00,  1.3973e+00,  1.5087e+00,  3.1063e-01, -6.3307e-01,\n",
      "          1.3946e+00, -6.8660e-01,  1.0063e-01,  1.1746e+00,  1.4453e+00,\n",
      "          1.1000e+00,  1.5403e-01],\n",
      "        [-7.0227e-01, -8.7493e-01, -8.7010e-01, -2.7868e-01,  1.5919e-01,\n",
      "         -6.0408e-01,  5.7071e-01,  7.9180e-01,  6.7714e-01,  5.2086e-01,\n",
      "          9.5282e-01,  1.1093e+00],\n",
      "        [ 1.0912e+00,  1.7182e+00,  1.4404e+00,  1.8055e-01,  1.5883e+00,\n",
      "          1.2720e+00,  3.8189e-01,  1.8194e+00,  1.0628e+00, -1.3343e+00,\n",
      "         -4.3028e-01, -9.3259e-01],\n",
      "        [-1.4266e+00, -1.4949e+00, -1.2137e+00, -7.6487e-01,  6.8093e-01,\n",
      "         -6.5604e-01, -6.7499e-01,  3.5968e-01, -5.0836e-01, -1.2884e-01,\n",
      "          1.3936e-01,  1.7280e+00],\n",
      "        [ 4.3402e-01, -3.8370e-01,  8.6572e-01,  8.2279e-01, -1.4198e+00,\n",
      "          1.9971e-01, -1.4820e+00, -1.4638e+00,  9.7722e-02,  2.3537e-01,\n",
      "         -6.4661e-01,  1.3772e+00],\n",
      "        [ 1.1023e-01,  8.7915e-01, -6.6941e-01, -4.7831e-01, -1.2060e+00,\n",
      "         -1.0199e-01,  7.9598e-01, -1.4753e+00,  7.9020e-01,  3.2685e-01,\n",
      "         -1.0724e+00, -2.8973e-01]]), tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 0., 1., 1.])]\n"
     ]
    }
   ],
   "source": [
    "# Test the data loader\n",
    "batch = next(iter(train_loader))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackPainNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer_2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.layer_out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm_1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.relu(self.layer_1(x))\n",
    "        x = self.batchnorm_1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BackPainNN(\n",
       "  (layer_1): Linear(in_features=12, out_features=64, bias=True)\n",
       "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (batchnorm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm_2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BackPainNN(12, 64, 1).to(device=device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuract(pred, truth):\n",
    "    \n",
    "    y_pred_tag = torch.round(torch.sigmoid(pred))\n",
    "    \n",
    "    correct = torch.eq(y_pred_tag, truth).sum().item()\n",
    "    return correct / len(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.53308 | Accuracy: 0.73\n",
      "Epoch: 1 | Loss: 0.44119 | Accuracy: 0.77\n",
      "Epoch: 2 | Loss: 0.28077 | Accuracy: 0.88\n",
      "Epoch: 3 | Loss: 0.27737 | Accuracy: 0.88\n",
      "Epoch: 4 | Loss: 0.19717 | Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss: 0.21611 | Accuracy: 0.90\n",
      "Epoch: 6 | Loss: 0.18345 | Accuracy: 0.93\n",
      "Epoch: 7 | Loss: 0.19590 | Accuracy: 0.94\n",
      "Epoch: 8 | Loss: 0.13480 | Accuracy: 0.93\n",
      "Epoch: 9 | Loss: 0.10743 | Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    epoch_loss, epoch_accuracy = 0, 0\n",
    "    for X, y in train_loader:\n",
    "        \n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_logits = model(X)\n",
    "        \n",
    "        # print(y_logits.shape)\n",
    "        # print(y.shape)\n",
    "        \n",
    "        loss = loss_fn(y_logits.squeeze(), y)\n",
    "        acc = binary_accuract(y_logits.squeeze(), y)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_accuracy += acc\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_loss /= len(train_loader)\n",
    "    epoch_accuracy /= len(train_loader)\n",
    "    \n",
    "    print(f\"Epoch: {epoch} | Loss: {epoch_loss:.5f} | Accuracy: {epoch_accuracy:.2f}\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(0., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32),\n",
       " array(1., dtype=float32)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred_list = []\n",
    "with torch.inference_mode():\n",
    "    for test_batch in test_loader:\n",
    "        \n",
    "        test_batch = test_batch.to(device)\n",
    "        logits = model(test_batch)\n",
    "        \n",
    "        y_test_pred = torch.round(torch.sigmoid(logits))\n",
    "        y_pred_list.append(y_test_pred.squeeze().cpu().numpy())\n",
    "\n",
    "y_pred_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 10],\n",
       "       [10, 64]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66        29\n",
      "           1       0.86      0.86      0.86        74\n",
      "\n",
      "    accuracy                           0.81       103\n",
      "   macro avg       0.76      0.76      0.76       103\n",
      "weighted avg       0.81      0.81      0.81       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"BackPain.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8688, -0.2905, -1.0583, -0.9021,  1.0449, -0.7341, -1.2222, -0.6909,\n",
      "         -1.4731,  0.1005, -1.0095,  0.6006]])\n",
      "tensor([[-0.4327]])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.load(MODEL_NAME)\n",
    "\n",
    "X = next(iter(test_loader))\n",
    "\n",
    "print(X)\n",
    "\n",
    "loaded_model = BackPainNN(12, 64, 1)\n",
    "loaded_model.load_state_dict(weights)\n",
    "\n",
    "loaded_model.eval()\n",
    "with torch.inference_mode():\n",
    "    \n",
    "    preds = loaded_model(X)\n",
    "    \n",
    "    print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Backpain_Scaler.bin']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the scaler so that it can be loaded later for inference\n",
    "\n",
    "joblib.dump(scaler, \"Backpain_Scaler.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
